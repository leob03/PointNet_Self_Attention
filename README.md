# PointNet with Self-Attention residual layers
This repository is an implementation of a final course project that studied the most influential neural architecture for point cloud understanding called PointNet with the ambition to improve its accuracy using Self-Attention Layers from the famous Transformer architecture.

<div align="center">
  <img src="PointNet_w_SA2.png" alt="Project Description" style="width:350px;height:500px;">
</div>

&nbsp;

<p align="center">
  Some visual results of the Semantic Segmentation algorithm:
  <br>
  <img src="./gif/results_PNA.gif" alt="Image Description" width="400" height="300">
</p>
